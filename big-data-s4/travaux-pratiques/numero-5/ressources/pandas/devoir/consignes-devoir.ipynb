{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avant-propos : Pour les utilisateurs de Google colab\n",
    "\n",
    "Petit apparté pour les utilisateurs de google colab. Pour utiliser la méthode `pd.read_csv()`, il faudra rajouter quelques lignes de codes supplémentaires pour pouvoir charger un fichier, les voici.\n",
    "\n",
    "\n",
    "```python\n",
    "# Première cellule jupyter\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "```\n",
    "\n",
    "```python\n",
    "# Seconde cellule jupyter\n",
    "import io\n",
    "import pandas as pd\n",
    "# Très important : le nom du fichier passé en paramètre de la fonction \"uploaded\" doit avoir le même nom que le fichier que vous avez uploadé\n",
    "df = pd.read_csv(io.BytesIO(uploaded['nom-du-fichier-uploader.csv']))\n",
    "```\n",
    "\n",
    "- [Voir plus  d'informations sur le chargement de fichiers externes avec Google colab](https://towardsdatascience.com/3-ways-to-load-csv-files-into-colab-7c14fcbdcb92)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but de cette pratique, notée, est de d'analyser un DataFrame (issu d'un fichier .csv/.xls(x) ou encore .sql) que vous aurez choisi  (sauf ceux qu'on a utilisés) et d'en tirer des conclusions. Autrement dit, vous devez vous poser des questions sur votre sujet pour ensuite en tirer des résultats (variables ou DataFrame).\n",
    "\n",
    "Si vous ne savez pas où trouver des datasets, vous pourrez en trouver ici :\n",
    "\n",
    "- [Voir site des données ouvertes du gouvernement](https://www.data.gouv.fr/)\n",
    "- [Voir site des données ouvertes de l'insee](https://www.insee.fr/fr/statistiques?categorie=1)\n",
    "- [Voir moteur de recherche de Google dédié aux datasets](https://datasetsearch.research.google.com/)\n",
    "- [Voir site des données ouvertes de l'éducation nationale](https://data.education.gouv.fr/)\n",
    "- [Voir ensemble de datasets récoltés pour le cours](https://github.com/DanYellow/cours/tree/main/big-data-s4/datasets)\n",
    "  - Note : il y a un fichier txt parfois, il explique les colonnes quand elles sont trop sibyllines. [Plus d'infos ici](https://raw.githubusercontent.com/DanYellow/cours/main/big-data-s4/datasets/__guide-datasets.txt)\n",
    "- [Voir ensemble de sites pour datasets](https://github.com/DanYellow/cours/blob/main/big-data-s4/datasets/_liste-sites-source-pour-datasets.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rendu attendus\n",
    "\n",
    "- Une archive nommée nom-prénom contenant :\n",
    "  - Votre notebook \n",
    "  - Votre dataset\n",
    "\n",
    "# Votre liste à faire\n",
    "- [x] Lire les consignes\n",
    "- [ ] Trouver un jeu de données pertinent\n",
    "- [ ] Explorer le jeu de données\n",
    "- [ ] Trouver des questions (5) pertinentes \n",
    "- [ ] Filtrer le jeu de données pour répondre à vos questions\n",
    "- [ ] Rédiger les conclusions\n",
    "- [ ] Faire une archive nommée avec mon nom-prénom contenant :\n",
    "  - [ ] Votre notebook\n",
    "    - [ ] L'option \"Run All\" fonctionne sans problème, Jupyter n'affiche aucune erreur\n",
    "  - [ ] Votre dataset (pas grave s'il est dans un sous-dossier)\n",
    "  - [ ] Le barème (fichier .ods). N'oubliez pas de renommer la cellule associée avec notre nom-prénom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1 : Récupération / Chargement du fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"chemin-vers-dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2 : Exploration des données\n",
    "\n",
    "But : s'approprier le DataFrame, voir brièvement ce qu'on peut en tirer. Comprendre sa structure, voici les méthodes (liste non exhaustives) qui **peuvent** vous aider :\n",
    "- A quoi ressemble notre DataFrame ? # `df.head()` ou `df.tail()` ou `display(df)` / `display(df)` équivaut à faire `df.head()` et `df.tail()`\n",
    "- Combien de lignes/colonnes possède-t-il ? # `df.shape`\n",
    "- Quel est le type des données ? # `df.dtypes.values.tolist()`\n",
    "- Quels sont les noms des colonnes ? # `df.columns.values.tolist()`\n",
    "- Existe-il des données absentes ou nulles ? # `df.isnull().sum()` ou `df.isna().sum()`\n",
    "- Quelles données statistiques ressortent de mon jeu de données ? # `df.describe()`\n",
    "- Combien de valeurs uniques existe-t-il ? # `df.value_counts()`\n",
    "- Quelle est valeur min/max de certaines colonnes ? # `df['colonne'].min()/.max()`\n",
    "- Quelles sont les valeurs uniques pour une colonne / dataset ? # `df['colonne'].unique() / df.unique()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3 : Nettoyage des données\n",
    "\n",
    "But : retirer toutes les valeurs qui pourraient nous poser problème et/ou les formatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 4 : Modélisation\n",
    "But : Définir les informations qui peuvent nous intéresser. Se poser des questions pertinentes et y répondre avec des DataFrame ou encore des valeurs et en tirer quelque chose. Et bien évidemment explorer ce nouveau Dataframe nettoyé pour vous assurer que tout est bon.\n",
    "Notes : Vos questions (minimum 4) doivent être écrites dans le Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 5 : Interprétation\n",
    "\n",
    "But : Interpréter vos modélisations, le résultat de vos Dataframe"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ed06d07b9ff369db6ed7b53447be18709da67cd911d838d72fee7fecb26667a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
