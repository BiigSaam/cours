{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pandas - partie 2\n",
    "\n",
    "![logo pandas](https://pandas.pydata.org/docs/_static/pandas.svg)\n",
    "\n",
    "Dans la première partie, nous avons vous l'objet qui se trouve au coeur de la librairie pandas, cousine de numpy. Pour rappel, un dataframe (ou jeu de données) ressemble à un tableau excel où chaque colonne possède un nom. Ainsi, il est dit que les données d'un dataframe sont tabulaires.\n",
    "\n",
    "La partie 1 du TP pandas a été l'occasion de travailler avec de petits dataframes (écrits à la main), toutefois en Big Data, ce n'est pas des dataframes de moins de 10 lignes avec lesquels nous travaillons, mais en général plus de 100 000. Bien évidemment, nous n'allons pas écrire des fichiers de plus de 100 000 à la main et encore moins dans un notebook, et ici qu'entre en jeu le format csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comma-separated values ou csv est un format de fichier représentant des valeurs tabulaires sous forme de valeurs séparées par des virgules. \n",
    "![csv](https://raw.githubusercontent.com/DanYellow/cours/main/big-data-s4/travaux-pratiques/numero-5/ressources/_images/csv.jpg)\n",
    "- [En savoir plus sur le format csv (wikipedia)](https://fr.wikipedia.org/wiki/Comma-separated_values)\n",
    "\n",
    "Il est possible de transformer un fichier tableur (.xls, .xslx, .odf...) en fichier csv, il suffit juste à la sauvegarde de préciser le format csv. \n",
    "\n",
    "![sauvegarde-csv](../_images/sauvegarde-csv.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et ce format est très bien géré par pandas, et ce, même quand le fichier possède des millions de lignes. Pour ce faire il nous faut utiliser la méthode `pd.read_csv(\"chemin-du-fichier.csv\")`. Bien évidemment, il faut penser à importer pandas avant avec la ligne suivante `import pandas as pd`.\n",
    "\n",
    "Note : Il est possible de charger des fichiers .xls(x) ou encore .json, mais _historiquement_ on utilise plus le format csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pour les utilisateurs de Google colab\n",
    "\n",
    "Petit apparté pour les utilisateurs de google colab. Pour utiliser la méthode `pd.read_csv()`, il faudra rajouter quelques lignes de codes supplémentaires pour pouvoir charger un fichier, les voici.\n",
    "\n",
    "\n",
    "```python\n",
    "# Première cellule jupyter\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "```\n",
    "\n",
    "```python\n",
    "# Seconde cellule jupyter\n",
    "import io\n",
    "# Très important : le nom du fichier passé en paramètre de la fonction \"uploaded\" doit avoir le même nom que le fichier que vous avez uploadé\n",
    "df = pd.read_csv(io.BytesIO(uploaded['nom-du-fichier-uploader.csv']))\n",
    "```\n",
    "\n",
    "- [Voir plus  d'informations sur le chargement de fichiers externes avec Google colab](https://towardsdatascience.com/3-ways-to-load-csv-files-into-colab-7c14fcbdcb92)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pour charger un fichier distant (un serveur)\n",
    "\n",
    "Bien que nous fassions du Python depuis Jupyter, nous avons toujours accès aux méthodes et classes natives de Python dont \"request\". Elle nous permet d'effectuer des rêquetes serveurs et donc de charger des fichiers\n",
    "\n",
    "request.urlretrieve (\"https://s3-eu-west-1.amazonaws.com/static.oc-static.com/prod/courses/files/Parcours_data_scientist/decouvrez-les-librairies-python-pour-la-data-science/hubble_data.csv\", \"be.csv\")\n",
    "hubble = pd.read_csv(\"ble.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et ces données, on les trouve où ? Il existe beaucoup de sources, dans le cadre de cette pratique, nous allons utiliser le site des données ouvertes du gouvernement français (et de l'insee, les deux sont liés). Et plus précisément celui des naissances de 1900 et 2019 par département (fichier présent dans la ressource).\n",
    "\n",
    "- [Voir site des données ouvertes du gouvernement](https://www.data.gouv.fr/)\n",
    "- [Voir site des données ouvertes de l'insee](https://www.insee.fr/fr/statistiques?categorie=1)\n",
    "- [Voir moteur de recherche de Google dédié aux datasets](https://datasetsearch.research.google.com/)\n",
    "- [Voir site des données ouvertes de l'éducation nationale](https://data.education.gouv.fr/)\n",
    "- [Voir site de données ouvertes (souvent anglophones)](https://github.com/awesomedata/awesome-public-datasets)\n",
    "\n",
    "\n",
    "- [Voir source du fichier de données des prénoms - Ficher que nous allons utiliser pour la suite du TP](https://www.insee.fr/fr/statistiques/2540004?sommaire=4767262#consulter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Petite note** : Malgré la taille du fichier (~9 Mo), ce dernier possède plus de 3 500 000 lignes. Si on essaye d'ouvrir le fichier avec OpenOffice Calc (équivalent Open Source d'Excel), on a le droit au message suivant :\n",
    "![erreur chargement](https://raw.githubusercontent.com/DanYellow/cours/main/big-data-s4/travaux-pratiques/numero-5/ressources/_images/erreur-chargement-calc.jpg)\n",
    "Heureusement, nous utilisons pandas nous allons pouvoir ouvrir le fichier sans encombres.\n",
    "\n",
    "# Phase 1 : Récupération / Chargement du fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilisateurs de Google Colab\n",
    "# pensez bien à uploader le fichier dans cette cellule\n",
    "# avec le code plus haut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe pandas, pas de pandas, pas de DataFrame donc pas de manipulation de données tabulaires\n",
    "import pandas as pd\n",
    "# On charge le fichier dans une cellule spécifique. Pourquoi ? On veut éviter de charger ce gros fichier régulièrement.\n",
    "# Si nous utilisez Google Colab, ça devrait aller plus vite.\n",
    "liste_prenoms_source = pd.read_csv(\"datasets/naissances-par-departement-1900-2019.csv\", sep=\";\") # le fichier est chargé en tant que DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2 : Exploration des données\n",
    "Après avoir chargé un DataFrame, la première chose à faire est de l'explorer. Cette phase nous permet de savoir assez facilement et rapidement quel jeu de données on manipule, on essaye de répondre aux questions suivantes :\n",
    "- A quoi ressemble notre DataFrame ? # `df.head()` ou `df.tail()` ou `display(df)` / `display(df)` équivaut à faire `df.head()` et `df.tail()`\n",
    "- Combien de lignes/colonnes possède-t-il ? # `df.shape`\n",
    "- Quel est le type des données ? # `df.dtypes`\n",
    "- Quels sont les noms des colonnes ? # `df.columns`\n",
    "- Existe-il des données absentes ? # `df.isnull().sum()` ou `df.isna().sum()`\n",
    "- Quelles données statistiques ressortent de mon jeu de données ? # `df.describe()`\n",
    "- Combien de valeurs uniques existe-t-il ? # `df.value_counts()`\n",
    "- Quelle est valeur min/max de certaines colonnes ? # `df['colonne'].min()/.max()`\n",
    "- Quelles sont les valeurs uniques pour une colonne ? # `df['colonne'].unique()`\n",
    "\n",
    "Il n'est pas utile de répondre à toutes ces questions, toutefois, il faut au moins répondre aux questions suivantes : \n",
    "- A quoi ressemble notre DataFrame ?\n",
    "- Existe-il des données absentes ?\n",
    "\n",
    "Ces deux questions nous aideront beaucoup pour la phase suivante\n",
    "\n",
    "## A vous de coder\n",
    "Répondre en code aux questions posées plus haut, inutile de stocker ceci dans une variable, utiliser un simplement la fonction `display()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codez ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qu'observez-vous ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pourquoi les index ?\n",
    "\n",
    "Dans la précédente partie, nous avons vu qu'il était possible de définir des index dans un DataFrame, une fois défini, nous avions accès à la syntaxe `df.loc['mon_index']`. **Il faut comprendre que la définition de l'index a une importance quant aux performances de pandas.** Prenons le cas suivant : Nous souhaitons chercher toutes les occurences du prénom \"Pauline\" dans notre DataFrame. Nous pouvons écrire le code suivant.\n",
    "```python\n",
    "    liste_prenoms_source[liste_prenoms_source['preusuel'] == \"PAULINE\"]\n",
    "```\n",
    "Ou nous pouvons définir la colonne \"preusuel\" en tant qu'index puis faire une rechercher grâce à la propriété \".loc\".\n",
    "```python\n",
    "    liste_prenoms_source.set_index(\"preusuel\").loc['PAULINE']\n",
    "    # Note : L'opération \"set_index\" est coûteuse en terme de temps\n",
    "```\n",
    "Comparons les deux instructions (il est possible d'exécuter plusieurs cellules en même temps). L'opération `set_index` étant coûteuse, on va effectuer trois tests et calculer le temps d'exécution :\n",
    "- La recherche du prénom \"PAULINE\" sans index\n",
    "- La recherche du prénom \"PAULINE\" avec la colonne \"preusuel\" indexée + indexation de la colonne \"preusuel\"\n",
    "- La recherche du prénom \"PAULINE\" avec la colonne \"preusuel\" indexée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197 ms ± 5.32 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sexe</th>\n",
       "      <th>preusuel</th>\n",
       "      <th>annais</th>\n",
       "      <th>dpt</th>\n",
       "      <th>nombre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3350517</th>\n",
       "      <td>2</td>\n",
       "      <td>PAULINE</td>\n",
       "      <td>1900</td>\n",
       "      <td>01</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3350518</th>\n",
       "      <td>2</td>\n",
       "      <td>PAULINE</td>\n",
       "      <td>1900</td>\n",
       "      <td>02</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3350519</th>\n",
       "      <td>2</td>\n",
       "      <td>PAULINE</td>\n",
       "      <td>1900</td>\n",
       "      <td>03</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3350520</th>\n",
       "      <td>2</td>\n",
       "      <td>PAULINE</td>\n",
       "      <td>1900</td>\n",
       "      <td>04</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3350521</th>\n",
       "      <td>2</td>\n",
       "      <td>PAULINE</td>\n",
       "      <td>1900</td>\n",
       "      <td>05</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3356649</th>\n",
       "      <td>2</td>\n",
       "      <td>PAULINE</td>\n",
       "      <td>2019</td>\n",
       "      <td>93</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3356650</th>\n",
       "      <td>2</td>\n",
       "      <td>PAULINE</td>\n",
       "      <td>2019</td>\n",
       "      <td>94</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3356651</th>\n",
       "      <td>2</td>\n",
       "      <td>PAULINE</td>\n",
       "      <td>2019</td>\n",
       "      <td>95</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3356652</th>\n",
       "      <td>2</td>\n",
       "      <td>PAULINE</td>\n",
       "      <td>2019</td>\n",
       "      <td>974</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3356653</th>\n",
       "      <td>2</td>\n",
       "      <td>PAULINE</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>XX</td>\n",
       "      <td>3454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6137 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sexe preusuel annais  dpt  nombre\n",
       "3350517     2  PAULINE   1900   01       7\n",
       "3350518     2  PAULINE   1900   02      35\n",
       "3350519     2  PAULINE   1900   03       7\n",
       "3350520     2  PAULINE   1900   04      10\n",
       "3350521     2  PAULINE   1900   05       6\n",
       "...       ...      ...    ...  ...     ...\n",
       "3356649     2  PAULINE   2019   93       6\n",
       "3356650     2  PAULINE   2019   94      13\n",
       "3356651     2  PAULINE   2019   95       5\n",
       "3356652     2  PAULINE   2019  974      14\n",
       "3356653     2  PAULINE   XXXX   XX    3454\n",
       "\n",
       "[6137 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%timeit liste_prenoms_source[liste_prenoms_source['preusuel'] == \"PAULINE\"]\n",
    "display(liste_prenoms_source[liste_prenoms_source['preusuel'] == \"PAULINE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "435 ms ± 7.77 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit liste_prenoms_source.set_index(\"preusuel\").loc['PAULINE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.1 ms ± 586 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "preusuel_index = liste_prenoms_source.set_index(\"preusuel\")\n",
    "%timeit preusuel_index.loc['PAULINE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quels résultats observez-vous ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commandes magiques\n",
    "\n",
    "Vous avez remarqué que dans les cellules précédentes, nous avons utilisé `%timeit`, cette syntaxe est propre à jupyter, on appelle ceci une commande magique. Elles ajoutent de nouvelles fonctionnalités aux notebooks de façon très simple, ces fonctionnalités peuvent s'appliquer sur **une seule ligne de code** comme le code ci-dessous.\n",
    "\n",
    "```python\n",
    "%ma_commande_magique mon_code_python\n",
    "```\n",
    "\n",
    "ou du code sur plusieurs lignes (remarquez bien la présence double du signe pourcentage `%%`).\n",
    "\n",
    "```python\n",
    "%%ma_commande_magique \n",
    "mon_code_python\n",
    "```\n",
    "Dans le cas ci-dessus la commande magique s'applique sur toute la cellule. Ainsi le code de la première cellule contenant `%timeit` aurait pu être écrit de de la façon suivante.\n",
    "\n",
    "\n",
    "```python\n",
    "%%timeit \n",
    "liste_prenoms_source[liste_prenoms_source['preusuel'] == \"PAULINE\"]\n",
    "```\n",
    "\n",
    "**Attention :** Toutes les commandes magiques ne sont pas elligibles à la gestion multilignes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Il est possible de lister les commandes magiques avec la commande : %lsmagic\n",
    "%lsmagic\n",
    "\n",
    "# la commande %quickref affiche la documention des commandes\n",
    "%quickref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3 : Nettoyage de données\n",
    "\n",
    "Dans les grandes lignes, le nettoyage de données consiste à supprimer/modifier les mauvaises de données, elles peuvent être de plusieurs formes : \n",
    "- Une donnée / colonne manquante\n",
    "- Des données dupliquées\n",
    "- Une donnée au mauvais format\n",
    "- Une donnée incorrecte\n",
    "\n",
    "Il est préférable de nettoyer les données pour plusieurs raisons :\n",
    "- Eviter les problèmes de calculs (données manquantes, données aberrantes...)\n",
    "- Eviter les affichages étranges de graphiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemples de code pour nettoyer les données\n",
    "\n",
    "- Permet de supprimer lignes avec des données absentes\n",
    "Le paramètre \"inplace\" permet de faire muter le dataframe quand le paramètre est égale à \"True\", inplace=False renvoie un nouveau dataframe\n",
    "```python \n",
    "df.dropna(inplace = True)\n",
    "```\n",
    "\n",
    "- Permet de supprimer lignes avec des données non conformes\n",
    "```python \n",
    "df.drop(df[<nos conditions>].index)\n",
    "```\n",
    "\n",
    "- Permet de supprimer lignes avec des données dupliquées\n",
    "```python \n",
    "df.drop_duplicates()\n",
    "```\n",
    "\n",
    "- Permet de remplir les cases vides d'une colonne, par la valeur moyenne de la colonne\n",
    "La fonction retourne un nouveau dataframe, toutefois, il est possible de faire muter le dataframe en rajoutant le paramètre \"inplace = True\"\n",
    "```python \n",
    "df['nom_de_la_colonne'].fillna(df['nom_de_la_colonne'].mean())\n",
    "```\n",
    "\n",
    "- Permet de changer le type d'une colonne\n",
    "Ceci peut permettre, notamment de diminuer la taille en mémoire d'un dataset (`df.info(memory_usage='deep')`)\n",
    "```python \n",
    "df['nom_de_la_colonne'] = df['nom_de_la_colonne'].astype(nom_du_type)\n",
    "```\n",
    "\n",
    "- Permet d'appliquer une fonction sur une colonne (ne pas oublier de retourner la valeur)\n",
    "```python\n",
    "def ma_fonction(val):\n",
    "    return val + 2\n",
    "df['nom_de_la_colonne'] = df['nom_de_la_colonne'].apply(ma_fonction)\n",
    "```\n",
    "\n",
    "- Permet de filtrer les lignes par condition (& pour \"et\", | pour \"ou\")\n",
    "```python\n",
    "df[(df[\"nom_de_la_colonne\"] == \"valeur\") | (df[\"nom_de_la_colonne\"] == \"valeur\")]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A vous de coder\n",
    "\n",
    "A partir du DataFrame des prénoms, définir des dataframes correspondants aux critères suivants (une ligne, un nouvel dataframe) :\n",
    "\n",
    "- Contient 10 000 premières entrées concernant les naissances d'enfants de sexe féminin dans toute la France\n",
    "- Contient toutes les naissances d'enfants ayant votre prénom dans toute la France\n",
    "- Contient toutes les naissances de l'année 2001 dans le département du Val-d'Oise (95)\n",
    "- Contient toutes les naissances de l'année 2001 dans la région de votre choix (plusieurs départements) + une colonne contenant le nom de la région.\n",
    "- Contient toutes les naissances des années 1991, 2001 et 2011 dans toute la France"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contient 10 000 premières entrées concernant les naissances d'enfants de sexe féminin dans toute la France"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contient toutes les naissances d'enfants ayant votre prénom dans toute la France"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contient toutes les naissances de l'année 2001 dans le département du Val-d'Oise (95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contient toutes les naissances de l'année 2001 dans la région de votre choix (plusieurs départements) \n",
    "# + une colonne contenant le nom de la région"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contient toutes les naissances des années 1991, 2001 et 2011 dans toute la France"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En analyse de données, notre but est de se poser des questions et bien évidemment d'y répondre grâce à la donnée, pour enfin en conclure quelque chose. N'oubliez pas _qu'un problème bien posé est à moitié résolu_. Ce sont des questions qui vont piloter vos DataFrame, votre code, vos articles.\n",
    "\n",
    "# A vous de coder\n",
    "\n",
    "A partir du DataFrame des prénoms, répondre aux questions suivantes avec une variable ou un DataFrame :\n",
    "- Quel est le prénom masculin et féminin le plus populaire de l'année 1995 ?\n",
    "- Quel département a vu naître le plus de \"Jean\" (toutes années confondues) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quel est le prénom masculin et féminin le plus populaire de l'année 1995 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quel département a vu naître le plus de \"Jean\" (toutes années confondues) ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
